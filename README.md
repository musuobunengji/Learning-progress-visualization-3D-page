# ChapterGraph

**A Retrieval-Backed Knowledge Graph for Technical Documents**

ChapterGraph is an end-to-end backend system that builds, persists, and queries semantic relationships between chapters across multiple technical books. The project is designed as a **modular retrieval pipeline** rather than a monolithic ML demo, with clear separation between ingestion, enrichment, candidate generation, similarity scoring, persistence, and API exposure.

This repository emphasizes **engineering correctness, observability, and extensibility** over premature modeling complexity.

---

## âœ¨ Core Capabilities

* **Document Ingestion**
  Parse structured book content into normalized JSON representations.

* **Signal Enrichment**
  Derive chapter-level textual signals (e.g. `chapter_text`) used as inputs to retrieval models.

* **Multi-Stage Retrieval Pipeline**

  * Candidate generation (pruning search space)
  * Similarity scoring (TF-IDFâ€“based ranking)
  * Thresholding / filtering

* **Graph Construction**
  Generate directed, weighted edges between chapters representing semantic relatedness.

* **Persistent Storage (PostgreSQL)**
  Store books, chapters, and edges as first-class relational entities.

* **Retrieval-Backed API (FastAPI)**
  Expose compute and query endpoints backed by a real database.

---

## ğŸ§  Design Philosophy

### 1. Funnel-Based Retrieval (Classical IR)

The system follows a classical **funnel architecture**:

1. **Candidate Generation** â€“ fast, coarse pruning (avoid full pairwise comparison)
2. **Similarity Scoring** â€“ more expensive ranking (TF-IDF)
3. **Filtering** â€“ score threshold / top-k
4. **Persistence** â€“ store results for downstream use

This mirrors production-grade search and recommendation systems.

### 2. Interface-First, OO Design

Key components are defined via interfaces, enabling future extension without refactoring:

* Candidate generators (rule-based, TF-IDF tokenâ€“based, etc.)
* Similarity scorers (TF-IDF today, embeddings tomorrow)
* Retrieval pipeline orchestrator

### 3. Deliberate Model Choice

TF-IDF is used intentionally as the **first semantic baseline**:

* Deterministic
* Debuggable
* Interpretable

Embedding-based similarity is treated as a **future drop-in replacement**, not a prerequisite.

---

## ğŸ—‚ Project Structure

```text
feature_achievement/
â”œâ”€â”€ ingestion/              # Parse raw book content â†’ structured JSON
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ enrichment/             # Derive chapter-level signals (chapter_text, etc.)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ candidates/         # Candidate generation strategies
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ tfidf_token.py
â”‚   â”‚
â”‚   â”œâ”€â”€ similarity/         # Similarity scoring strategies
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ tfidf.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline.py         # RetrievalPipeline orchestrator
â”‚   â””â”€â”€ edge_generation.py  # Convert retrieval output â†’ graph edges
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ models.py           # Book / Chapter / Edge (SQLModel)
â”‚   â”œâ”€â”€ db.py               # Engine, session, init_db
â”‚   â””â”€â”€ crud.py             # Persistence helpers
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”œâ”€â”€ deps.py             # Dependency wiring
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ edges.py        # Compute + query edges
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_db.py          # Initialize database schema
â”‚
â””â”€â”€ pipeline.py             # Script-style pipeline entry (non-API)
```

---

## ğŸ—„ Database Schema (PostgreSQL)

### Book

* `id` (PK)
* `title`
* `created_at`

### Chapter

* `id` (PK)
* `book_id` (indexed)
* `chapter_text`
* `created_at`

### Edge

* `id` (PK)
* `from_chapter` (indexed)
* `to_chapter` (indexed)
* `score`
* `type` (e.g. `tfidf`)
* `created_at`

The schema enforces a **node-before-edge** persistence model, mirroring graph system best practices.

---

## ğŸš€ Running the Project

### 1ï¸âƒ£ Initialize Database

```bash
python -m feature_achievement.scripts.init_db
```

### 2ï¸âƒ£ Start API Server

```bash
uvicorn feature_achievement.api.main:app --reload
```

Open Swagger UI:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ”Œ API Endpoints

### `POST /compute-edges`

* Runs retrieval pipeline
* Persists books, chapters, and edges
* Designed for batch / MQ-style execution

### `GET /edges?book_id=...`

* Query all edges associated with a given book
* Returns both incoming and outgoing relationships

---

## ğŸ§ª Observability & Debugging

The pipeline is intentionally designed to allow inspection at every stage:

* Raw chapter text
* TF-IDF vectors
* Top-N similar chapters
* Persisted edges

This makes semantic errors diagnosable **before** introducing black-box models.

---

## ğŸ”® Future Extensions

* Embedding-based similarity (drop-in replacement)
* Asynchronous retrieval jobs (MQ / worker)
* Edge pagination & filtering
* Graph visualization (D3 / WebGL)
* Vector database integration

---

## ğŸ“Œ Summary

ChapterGraph is not a demo of a single model, but a **retrieval system**:

* Modular
* Inspectable
* Persisted
* API-backed

It is designed to scale in both **data volume** and **model sophistication** without architectural rewrites.
